#!/usr/bin/env python3
"""
SEAO â€” Pipeline automatisÃ© complet
====================================
Ã‰tape 1 : TÃ©lÃ©charge les fichiers JSON depuis DonnÃ©es QuÃ©bec
Ã‰tape 2 : Extrait et enrichit les donnÃ©es en CSV

Usage:
    # Tout faire d'un coup
    python pipeline_seao.py

    # Ã‰tape 1 seulement (tÃ©lÃ©charger)
    python pipeline_seao.py --download-only

    # Ã‰tape 2 seulement (extraire, si les JSON sont dÃ©jÃ  tÃ©lÃ©chargÃ©s)
    python pipeline_seao.py --extract-only

    # Filtrer par annÃ©e
    python pipeline_seao.py --years 2023 2024 2025 2026

    # Forcer le re-tÃ©lÃ©chargement
    python pipeline_seao.py --force

PrÃ©requis:
    pip install requests
"""

import json
import csv
import sys
import os
import time
import argparse
import hashlib
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import requests
except ImportError:
    print("âŒ Le module 'requests' est requis. Installez-le avec : pip install requests")
    sys.exit(1)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path(__file__).parent
INDEX_FILE = BASE_DIR / "index.json"
JSON_DIR = BASE_DIR / "json_files"
DATA_DIR = BASE_DIR / "data"

# Nombre de tÃ©lÃ©chargements simultanÃ©s
MAX_WORKERS = 3
# Pause entre les requÃªtes (secondes) pour ne pas surcharger le serveur
DELAY_BETWEEN_REQUESTS = 1.0
# Timeout pour le tÃ©lÃ©chargement (secondes)
DOWNLOAD_TIMEOUT = 300
# Nombre de tentatives en cas d'erreur
MAX_RETRIES = 3


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 0 : TÃ©lÃ©charger/mettre Ã  jour l'index
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INDEX_URL = "https://www.donneesquebec.ca/recherche/api/3/action/package_show?id=systeme-electronique-dappel-doffres-seao"


def download_index():
    """TÃ©lÃ©charge l'index des ressources SEAO depuis DonnÃ©es QuÃ©bec."""
    print("ğŸ“‹ TÃ©lÃ©chargement de l'index SEAO...")

    if INDEX_FILE.exists():
        print(f"   Index existant trouvÃ©: {INDEX_FILE}")
        with open(INDEX_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"   {data.get('nombre_ressources', '?')} ressources dans l'index")
        return data

    # Si pas d'index local, essayer de le tÃ©lÃ©charger
    try:
        resp = requests.get(INDEX_URL, timeout=30)
        resp.raise_for_status()
        api_data = resp.json()

        if api_data.get('success'):
            package = api_data['result']
            resources = package.get('resources', [])

            # Construire notre format d'index
            index = {
                "dataset": package.get('name', ''),
                "date_extraction": datetime.now().isoformat(),
                "nombre_ressources": len(resources),
                "ressources": []
            }

            for r in resources:
                if r.get('format', '').upper() == 'JSON' and r.get('url', '').endswith('.json'):
                    name = r.get('name', '') or r['url'].split('/')[-1]
                    # Extraire annÃ©e du nom de fichier
                    annee = None
                    for part in name.replace('_', '-').split('-'):
                        if len(part) == 8 and part.isdigit():
                            annee = int(part[:4])
                            break

                    index['ressources'].append({
                        'id': r.get('id', ''),
                        'nom': name,
                        'format': 'JSON',
                        'url': r['url'],
                        'taille': r.get('size', 0) or 0,
                        'taille_lisible': f"{(r.get('size', 0) or 0) / 1e6:.1f} Mo",
                        'annee': annee or 2021,
                        'mois': '',
                        'date_creation': r.get('created', ''),
                        'date_modification': r.get('last_modified', ''),
                    })

            with open(INDEX_FILE, 'w', encoding='utf-8') as f:
                json.dump(index, f, ensure_ascii=False, indent=2)

            print(f"   âœ… Index tÃ©lÃ©chargÃ©: {len(index['ressources'])} ressources JSON")
            return index
    except Exception as e:
        print(f"   âš ï¸ Impossible de tÃ©lÃ©charger l'index: {e}")
        print(f"   Assurez-vous que le fichier index.json est prÃ©sent dans {BASE_DIR}")
        sys.exit(1)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 1 : TÃ©lÃ©chargement des JSON
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_file(resource, force=False):
    """TÃ©lÃ©charge un fichier JSON depuis DonnÃ©es QuÃ©bec."""
    url = resource['url']
    nom = resource['nom']
    dest = JSON_DIR / nom

    # VÃ©rifier si dÃ©jÃ  tÃ©lÃ©chargÃ©
    if dest.exists() and not force:
        expected_size = resource.get('taille', 0)
        actual_size = dest.stat().st_size
        # TolÃ©rance de 10% sur la taille
        if expected_size == 0 or abs(actual_size - expected_size) / max(expected_size, 1) < 0.1:
            return {'status': 'skip', 'nom': nom, 'message': 'DÃ©jÃ  tÃ©lÃ©chargÃ©'}

    for attempt in range(MAX_RETRIES):
        try:
            resp = requests.get(url, timeout=DOWNLOAD_TIMEOUT, stream=True)
            resp.raise_for_status()

            with open(dest, 'wb') as f:
                for chunk in resp.iter_content(chunk_size=8192):
                    f.write(chunk)

            time.sleep(DELAY_BETWEEN_REQUESTS)
            return {'status': 'ok', 'nom': nom, 'size': dest.stat().st_size}

        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(5 * (attempt + 1))  # Backoff progressif
            else:
                return {'status': 'error', 'nom': nom, 'message': str(e)}

    return {'status': 'error', 'nom': nom, 'message': 'Max retries exceeded'}


def download_all(index, years=None, force=False):
    """TÃ©lÃ©charge tous les fichiers JSON."""
    JSON_DIR.mkdir(parents=True, exist_ok=True)

    resources = index['ressources']
    if years:
        resources = [r for r in resources if r.get('annee') in years]

    print(f"\nğŸ“¥ TÃ©lÃ©chargement de {len(resources)} fichiers JSON...")
    total_size = sum(r.get('taille', 0) for r in resources)
    print(f"   Taille estimÃ©e: {total_size/1e9:.1f} Go")

    results = {'ok': 0, 'skip': 0, 'error': 0}
    errors = []

    # TÃ©lÃ©chargement sÃ©quentiel (plus sÃ»r pour un serveur gouvernemental)
    for i, resource in enumerate(resources):
        print(f"   [{i+1}/{len(resources)}] {resource['nom']}...", end=' ', flush=True)
        result = download_file(resource, force=force)

        if result['status'] == 'ok':
            print(f"âœ… ({result['size']/1e6:.1f} Mo)")
            results['ok'] += 1
        elif result['status'] == 'skip':
            print("â­ï¸ dÃ©jÃ  prÃ©sent")
            results['skip'] += 1
        else:
            print(f"âŒ {result['message']}")
            results['error'] += 1
            errors.append(result)

    print(f"\nğŸ“Š RÃ©sumÃ©: {results['ok']} tÃ©lÃ©chargÃ©s, {results['skip']} dÃ©jÃ  prÃ©sents, {results['error']} erreurs")
    if errors:
        print("   Fichiers en erreur:")
        for e in errors:
            print(f"     - {e['nom']}: {e['message']}")

    return results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 2 : Extraction (rÃ©utilise extract_seao.py)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_extraction():
    """Lance l'extraction des JSON vers CSV enrichis."""
    extract_script = BASE_DIR / "extract_seao.py"

    if not extract_script.exists():
        print(f"âŒ Script d'extraction non trouvÃ©: {extract_script}")
        sys.exit(1)

    json_files = list(JSON_DIR.glob("*.json"))
    json_files = [f for f in json_files if f.name != 'index.json']

    if not json_files:
        print("âŒ Aucun fichier JSON trouvÃ© dans json_files/")
        sys.exit(1)

    print(f"\nğŸ”„ Extraction de {len(json_files)} fichiers JSON...")

    # Importer et utiliser directement les fonctions de extract_seao.py
    import importlib.util
    spec = importlib.util.spec_from_file_location("extract_seao", str(extract_script))
    extract_mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(extract_mod)

    DATA_DIR.mkdir(parents=True, exist_ok=True)

    all_rows = []

    for i, jf in enumerate(sorted(json_files)):
        print(f"   [{i+1}/{len(json_files)}] {jf.name}...", end=' ', flush=True)
        try:
            rows = extract_mod.process_file(jf)
            print(f"{len(rows)} contrats")
            all_rows.extend(rows)
        except Exception as e:
            print(f"âŒ {e}")

    # DÃ©duplication par ocid (garder le plus rÃ©cent)
    print(f"\nğŸ”„ DÃ©duplication...")
    seen = {}
    for row in all_rows:
        ocid = row.get('ocid', '')
        if not ocid:
            continue
        if ocid not in seen or (row.get('date', '') > seen[ocid].get('date', '')):
            seen[ocid] = row

    deduped = list(seen.values())
    print(f"   {len(all_rows):,} â†’ {len(deduped):,} contrats uniques")

    # Ã‰crire le CSV final
    out_path = DATA_DIR / "SEAO_ENRICHI.csv"
    extract_mod.write_csv(deduped, out_path)

    # Stats
    regions = Counter(r.get('region_admin', 'Inconnue') for r in deduped)
    qc = sum(1 for r in deduped if r.get('est_quebecois') == 1)
    years = Counter(r.get('annee_signature') or r.get('annee') for r in deduped)
    dep = sum(1 for r in deduped if (r.get('taux_depassement') or 0) > 0)

    print(f"\nğŸ“Š Statistiques finales:")
    print(f"   Contrats uniques: {len(deduped):,}")
    print(f"   Fournisseurs quÃ©bÃ©cois: {qc:,} ({100*qc/max(len(deduped),1):.1f}%)")
    print(f"   Avec dÃ©passement: {dep:,}")
    print(f"   AnnÃ©es: {sorted(set(str(y) for y in years.keys() if y))}")
    print(f"   Top rÃ©gions:")
    for reg, n in regions.most_common(10):
        print(f"     {reg}: {n:,}")

    return deduped


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    parser = argparse.ArgumentParser(
        description="Pipeline automatisÃ© SEAO : tÃ©lÃ©chargement + extraction",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python pipeline_seao.py                          # Tout faire
  python pipeline_seao.py --download-only          # TÃ©lÃ©charger seulement
  python pipeline_seao.py --extract-only           # Extraire seulement
  python pipeline_seao.py --years 2024 2025 2026   # AnnÃ©es spÃ©cifiques
  python pipeline_seao.py --force                  # Re-tÃ©lÃ©charger tout
        """
    )
    parser.add_argument('--download-only', action='store_true', help='TÃ©lÃ©charger les JSON seulement')
    parser.add_argument('--extract-only', action='store_true', help='Extraire les CSV seulement')
    parser.add_argument('--years', nargs='+', type=int, help='AnnÃ©es Ã  traiter (ex: 2024 2025 2026)')
    parser.add_argument('--force', action='store_true', help='Forcer le re-tÃ©lÃ©chargement')

    args = parser.parse_args()

    print("=" * 60)
    print("  SEAO â€” Pipeline automatisÃ©")
    print(f"  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # Charger l'index
    index = download_index()

    if not args.extract_only:
        # Ã‰tape 1 : TÃ©lÃ©chargement
        download_all(index, years=args.years, force=args.force)

    if not args.download_only:
        # Ã‰tape 2 : Extraction
        run_extraction()

    print("\n" + "=" * 60)
    print("  ğŸ‰ Pipeline terminÃ©!")
    print(f"  DonnÃ©es dans: {DATA_DIR}/SEAO_ENRICHI.csv")
    print(f"  Lancez le dashboard: streamlit run app.py")
    print("=" * 60)


if __name__ == '__main__':
    main()
